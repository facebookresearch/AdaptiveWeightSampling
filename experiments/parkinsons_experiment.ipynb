{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import hyperparams, model, dataloader\n",
    "from utils import results_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71796304",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"parkinsons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5650977",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Xtest, y, ytest = dataloader.load_data(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_per_algo = hyperparams.BY_DATASET[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627dbb47",
   "metadata": {},
   "source": [
    "# Run train, predict, sample, evaluate Active Learning loop.\n",
    "\n",
    "We start with `absolute loss based sampling` and `random sampling`.\n",
    "\n",
    "We cannot control how many points absloss will sample. Hence, we first sample based on absolute loss, then we calculate the sampling rate from the results, and then we use that sampling rate when we apply random sampling for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536fb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have stored results from our hyperparameter tuning run. Here we load the results, and will use the best hyperparameters per method.\n",
    "hyperparam_per_algo = hyperparams.BY_DATASET[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d28216",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "absloss_params = hyperparam_per_algo[\"absloss\"]\n",
    "\n",
    "results_absloss = model.sample_train_evaluate_loop(\n",
    "    X, y, Xtest, ytest, mode=\"absloss\", **absloss_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "absloss_mean_sampling_prob = np.mean(results_absloss[\"probs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "absloss_mean_sampling_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_params = hyperparam_per_algo[\"random\"]\n",
    "\n",
    "results_rand = model.sample_train_evaluate_loop(\n",
    "    X, y, Xtest, ytest, mode=\"random\", verbose=True, **(rand_params | {\"pz0\": absloss_mean_sampling_prob})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3d17a1",
   "metadata": {},
   "source": [
    "We now run the Active Learning loop for `Polyak absloss`. We aim to match the sampling probability that we achieved with `absloss_mean_sampling_prob`.\n",
    "\n",
    "We do this by using Polyak's omega parameter to scale up or down the sampling probabilities. We continue these omega adjustments until the mean sampling probability of `absloss_mean_sampling_prob` matches the mean sampling probability that we obtained with `absloss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b18a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_epsilon = 0.001\n",
    "\n",
    "results_polyak_absloss = None\n",
    "while results_polyak_absloss is None or abs(np.mean(results_absloss[\"probs\"]) - np.mean(results_polyak_absloss[\"probs\"])) > pz_epsilon:\n",
    "    results_polyak_absloss = model.sample_train_evaluate_loop(\n",
    "        X, y, Xtest, ytest, mode=\"polyak_absloss\", verbose=True, \n",
    "        **hyperparam_per_algo[\"polyak_absloss\"]\n",
    "    )\n",
    "    hppa = hyperparam_per_algo[\"polyak_absloss\"]\n",
    "    hppa[\"omega\"] *= np.mean(results_absloss[\"probs\"]) / np.mean(results_polyak_absloss[\"probs\"])\n",
    "    hyperparam_per_algo[\"polyak_absloss\"] = hppa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a85ba",
   "metadata": {},
   "source": [
    "We now run the Active Learning loop for `Polyak random`. For a fair comparison we again need to match the sampling rate to the one that we observed for absloss. Since Polyak random applies random sampling, we can simply set the sampling rate with `pz0` like we did for random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_polyak_random = model.sample_train_evaluate_loop(\n",
    "    X, y, Xtest, ytest, mode=\"polyak_random\", verbose=True, \n",
    "    **hyperparam_per_algo[\"polyak_absloss\"] | {\"pz0\": absloss_mean_sampling_prob}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33459c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_absloss_lr = model.sample_train_evaluate_loop(\n",
    "    X, y, Xtest, ytest, mode=\"absloss-lr-refit\", verbose=True, \n",
    "    **hyperparam_per_algo[\"absloss_lr\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b5671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_polyak_absloss_lr = model.sample_train_evaluate_loop(\n",
    "    X, y, Xtest, ytest, mode=\"polyak_absloss-lr-refit\", verbose=True, \n",
    "    **hyperparam_per_algo[\"polyak_absloss_lr\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19aba5",
   "metadata": {},
   "source": [
    "# Create figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697466c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = results_to_df(\n",
    "    {\n",
    "        \"random\": results_rand,\n",
    "        \"absloss\": results_absloss,\n",
    "        \"polyak_absloss\": results_polyak_absloss,\n",
    "        \"polyak_random\": results_polyak_random\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34831e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "ax = sns.lineplot(\n",
    "    data=plot_df,\n",
    "    x=\"iteration\", \n",
    "    y=\"mean_train_loss\",\n",
    "    hue=\"method\",\n",
    "    linewidth=2\n",
    ")\n",
    "legend = ax.get_legend()\n",
    "legend.set_title('')\n",
    "ax.set_xlim((0, 140))\n",
    "\n",
    "ax.set(ylabel=\"average \\ncross-entropy loss\")\n",
    "\n",
    "plt.savefig(f\"figure1_{dataset_name}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a345f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This figure plots the number of sampled points (i.e. the cost) against the loss. \n",
    "# Note the cost may be slightly different for different methods, this is because we only fixed the sampling rate *in expectation* by holding the average sampling probability constant\n",
    "# The actual realized number of sampled points may still vary by method. Note that when these differ too much then the results are likely unreliable and it is wise to re-run. \n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "ax = sns.lineplot(\n",
    "    data=plot_df,\n",
    "    x=\"cost\", \n",
    "    y=\"mean_train_loss\",\n",
    "    hue=\"method\",\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "ax.set(ylabel=\"average cross entropy loss\")\n",
    "\n",
    "legend = ax.get_legend()\n",
    "legend.set_title('')\n",
    "\n",
    "plt.savefig(f\"figure5_{dataset_name}.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5381f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_df[plot_df[\"method\"].isin([\"absloss\", \"polyak_absloss\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e300f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "ax = sns.lineplot(\n",
    "    data=plot_df,\n",
    "    x=\"iteration\", \n",
    "    y=\"mean_test_loss\",\n",
    "    hue=\"method\",\n",
    "    linewidth=2\n",
    ")\n",
    "ax.set_xlim((0, 140))\n",
    "\n",
    "legend = ax.get_legend()\n",
    "legend.set_title('')\n",
    "\n",
    "ax.set(ylabel=\"average test set loss\")\n",
    "\n",
    "plt.savefig(f\"figure6_icml_{dataset_name}.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "ax = sns.lineplot(\n",
    "    data=plot_df,\n",
    "    x=\"iteration\", \n",
    "    y=\"mean_test_accuracy\",\n",
    "    hue=\"method\",\n",
    "    linewidth=2\n",
    ")\n",
    "ax.set_xlim((0, 140))\n",
    "ax.set(ylabel=\"average test set accuracy\")\n",
    "\n",
    "legend = ax.get_legend()\n",
    "legend.set_title('')\n",
    "\n",
    "plt.savefig(f\"figure7_{dataset_name}.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03277ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = results_to_df(\n",
    "    {\n",
    "        \"polyak_absloss\": results_polyak_absloss,\n",
    "        \"polyak_absloss_estimator\": results_polyak_absloss_lr\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab381e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "ax = sns.lineplot(\n",
    "    data=plot_df,\n",
    "    x=\"iteration\", \n",
    "    y=\"mean_train_loss\",\n",
    "    hue=\"method\",\n",
    "    linewidth=2\n",
    ")\n",
    "legend = ax.get_legend()\n",
    "legend.set_title('')\n",
    "ax.set_xlim((0, 140))\n",
    "\n",
    "ax.set(ylabel=\"average \\ncross-entropy loss\")\n",
    "\n",
    "plt.savefig(f\"figure2_{dataset_name}.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd264ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "ax = sns.lineplot(\n",
    "    data=plot_df,\n",
    "    x=\"iteration\", \n",
    "    y=\"cost\",\n",
    "    hue=\"method\",\n",
    "    linewidth=2\n",
    ")\n",
    "legend = ax.get_legend()\n",
    "legend.set_title('')\n",
    "\n",
    "ax.set(ylabel=\"sampled labels\")\n",
    "\n",
    "plt.savefig(f\"figure8_{dataset_name}.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c1142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
